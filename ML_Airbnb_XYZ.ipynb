{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "855c3f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "19c03947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "import collections\n",
    "import gender_guesser.detector as gender\n",
    "from textblob import TextBlob\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50952fd0",
   "metadata": {},
   "source": [
    "# Basic Understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "695661d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48895, 16)\n"
     ]
    }
   ],
   "source": [
    "odf = pd.read_csv('C:\\\\Users\\\\xzhao\\\\Data\\\\AB_NYC_2019.csv')\n",
    "df = pd.read_csv('C:\\\\Users\\\\xzhao\\\\Data\\\\AB_NYC_2019.csv')\n",
    "# df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "48564706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "c6937573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "72530647",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mannual adjustment\n",
    "remove 0 dollar listing, they are rare\n",
    "switch to '' on Nan in name\n",
    "over write zero reviews in 2019 as reviewed in 2019YE\n",
    "over wirte brand new listers' relevant reviews as 0, and change data type\n",
    "'''\n",
    "\n",
    "df =df[df['price']!=0]\n",
    "df['name'] = df['name'].fillna('')\n",
    "df['last_review'] = df['last_review'].fillna('2019-12-31')\n",
    "df['reviews_per_month'] = df['reviews_per_month'].fillna('0')\n",
    "df['reviews_per_month']= df['reviews_per_month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "58fa4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "understand feature\n",
    "unique count and if less than 20, unique value\n",
    "Nan samples\n",
    "data description\n",
    "'''\n",
    "def ud(feature):\n",
    "    print('unique value count', df[feature].nunique())\n",
    "    if df[feature].nunique()<20:\n",
    "        print('unique value', df[feature].unique())\n",
    "    print('empty records:',  df[feature].isna().sum(), '\\n',df[df[feature].isna()])\n",
    "    print('data description:', df[feature].describe())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e83611b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "111e73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('host_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b045cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('host_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "5edfcec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('neighbourhood_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "161f5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('neighbourhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "73c661e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('room_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "b1ebc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('price')\n",
    "# df[df['price'] >150]\n",
    "# df[df['number_of_reviews'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "2ccabe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('minimum_nights')\n",
    "# df.groupby('minimum_nights').size()\n",
    "# df[df['minimum_nights'] > 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "7e97aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('number_of_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "55636042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('last_review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "f9dbadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('reviews_per_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "274a4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no last review  means review per month =0, basically brand new listers\n",
    "# df[df['last_review'].isna() & df['reviews_per_month'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "7b5cef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is total listings managed accross all airbnb under their name (self manaage + co host)\n",
    "# ud('calculated_host_listings_count')\n",
    "# df[df['calculated_host_listings_count'] >300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "c3f4cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ud('availability_365')\n",
    "# df[df['availability_365'] ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "206a3961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48884, 16)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "f444ec45",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "You have to supply one of 'by' and 'level'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27620\\3220279162.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7714\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mby\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7715\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You have to supply one of 'by' and 'level'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7716\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: You have to supply one of 'by' and 'level'"
     ]
    }
   ],
   "source": [
    "# df.groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129b3ae",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "27c5e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pain feature\n",
    "def paint(feature):\n",
    "    sns.scatterplot(x=feature, y='price',data=df,alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "8b01b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paint('neighbourhood_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204cfa3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# odf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9fb05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "3 approach to feature:drop, engineer+encode, simple encode\n",
    "'id', \n",
    "'name', extrac info unavailabe from other columns then one hot encode\n",
    "'host_id', \n",
    "'host_name', guess host gender\n",
    "'neighbourhood_group', straight one hot\n",
    "'neighbourhood', straight one hot\n",
    "'latitude', 'longitude', figure out how to use later\n",
    "'room_type', one hot\n",
    "'price', target\n",
    "'minimum_nights', label encode, >50\n",
    "'number_of_reviews', label encode, <50\n",
    "'last_review', break down to lr_year, lr_month, lr_day_of_week then onehot\n",
    "'reviews_per_month', label <3\n",
    "'calculated_host_listings_count', label <20\n",
    "'availability_365', sort value take top 5 as wide variaty\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "convert name column to a list of words appeared\n",
    "screen out nolist then out put top N frequent word\n",
    "'''\n",
    "allwords = list(df['name'].str.cat(sep=' ').split())\n",
    "nolist = ['in','to','the','with','and','of','room','near','&','-','east']\n",
    "words = []\n",
    "for word in allwords:\n",
    "    if word.lower() not in nolist:\n",
    "        words.append(word.lower())\n",
    "        \n",
    "def topNwords(word_list,N):\n",
    "    # Count the frequency of each word\n",
    "    word_freq = collections.Counter(word_list)\n",
    "\n",
    "    # Get the top N most common words\n",
    "    top_words = word_freq.most_common(N)\n",
    "\n",
    "    # Print the top N most common words\n",
    "    for word, freq in top_words:\n",
    "        print(word, freq)\n",
    "\n",
    "print(len(words)\n",
    "#       ,'\\n', words\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topNwords(words,100)\n",
    "\n",
    "'''\n",
    "use df[df['name'].fillna('').str.contains('heart')] to mannually check name\n",
    "possible 1/0 types:\n",
    "\n",
    "cozy,coziest vs \n",
    "spacious,large, huge,big vs\n",
    "sunny, sun- , bright vs \n",
    "modern, luxury, prime,  vs\n",
    "garden vs\n",
    "'''\n",
    "ec_dic = {'small':['cozy','coziest'],\n",
    "            'big':['spacious','large', 'huge','big'],\n",
    "            'light':['sunny', 'sun-', 'bright'],\n",
    "            'pres':['modern', 'luxury', 'prime'],\n",
    "            'garden':['garden']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f355b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_name_column(df, mapping_dict):\n",
    "    encoded_columns = {}\n",
    "    for col_name, keywords in mapping_dict.items():\n",
    "        encoded_col = df['name'].apply(lambda x: 1 if any(word in str(x).lower() for word in keywords) else 0)\n",
    "        encoded_columns[col_name] = encoded_col\n",
    "    encoded_df = pd.DataFrame(encoded_columns)\n",
    "    return pd.concat([df, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_name_column(df, ec_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb91855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "convert host_name to string\n",
    "guess host gender based on host_name then onehot encode it\n",
    "'''\n",
    "\n",
    "df['host_name'] = df['host_name'].astype(str)\n",
    "df['host_name'].dtype\n",
    "# Create instance of gender detector\n",
    "d = gender.Detector()\n",
    "\n",
    "# Define function to return gender based on name\n",
    "def get_gender(name):\n",
    "    gender = d.get_gender(name.title())\n",
    "    if gender == 'male' or gender == 'female':\n",
    "        return gender\n",
    "    else:\n",
    "        return 'androgynous'\n",
    "\n",
    "# Apply the function to the 'name' column of the DataFrame and create a new 'gender' column\n",
    "df['gender'] = df['host_name'].apply(get_gender)\n",
    "\n",
    "# One-hot encode the 'gender' column\n",
    "df = pd.concat([df, pd.get_dummies(df['gender'])], axis=1)\n",
    "\n",
    "# Drop the original 'gender' column\n",
    "df = df.drop('gender', axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc76146",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "general encoding methods:\n",
    "one hot can be functioned\n",
    "target is tougher to generalize, wirte individually\n",
    "'''\n",
    "def one_hot_encode(df, feature):\n",
    "    # Perform one-hot encoding\n",
    "    one_hot = pd.get_dummies(df[feature], prefix=feature)\n",
    "\n",
    "#     # drop base feature \n",
    "#     df = df.drop(feature, axis=1)\n",
    "    \n",
    "    # Add the encoded columns to the original DataFrame\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    \n",
    "    print(df.shape)\n",
    "    print('feature_gain:', df[feature].nunique())\n",
    "    \n",
    "#     Return the modified DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a4329",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = one_hot_encode(df, 'neighbourhood_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_encode(df, 'neighbourhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13efc1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = one_hot_encode(df, 'room_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "debe0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "last review feature engineering\n",
    "'''\n",
    "df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "df['lr_year'] = df['last_review'].dt.year\n",
    "df['lr_month'] = df['last_review'].dt.month\n",
    "df['lr_day'] = df['last_review'].dt.day\n",
    "df['lr_day_of_week'] = df['last_review'].dt.dayofweek\n",
    "#dayoftheweek Monday=0, Sunday=6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "39eca72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48884, 266)\n",
      "feature_gain: 9\n",
      "(48884, 278)\n",
      "feature_gain: 12\n",
      "(48884, 309)\n",
      "feature_gain: 31\n",
      "(48884, 316)\n",
      "feature_gain: 7\n"
     ]
    }
   ],
   "source": [
    "df = one_hot_encode(df, 'lr_year')\n",
    "df = one_hot_encode(df, 'lr_month')\n",
    "df = one_hot_encode(df, 'lr_day')\n",
    "df = one_hot_encode(df, 'lr_day_of_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "77d57af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of minimum nights\n",
    "df['long_stay'] = df['minimum_nights'].apply(lambda x: 1 if x >50 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d99d2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of revies label\n",
    "df['few_reviews'] = df['number_of_reviews'].apply(lambda x: 1 if x <50 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "95a83754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review per month label\n",
    "df['few_monthly_reviews'] = df['reviews_per_month'].astype(int).apply(lambda x: 1 if x <3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "baf253ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculated host listing count label\n",
    "df['few_total_listing'] = df['calculated_host_listings_count'].apply(lambda x: 1 if x <20 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "6facc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "availability grouped to find high variaty days\n",
    "label encode high variaty days\n",
    "'''\n",
    "wide_variaty_availability = df.groupby('availability_365').size().sort_values(ascending=False).head(5).index\n",
    "df['wide_variaty'] = df['availability_365'].apply(lambda x: 1 if x in wide_variaty_availability else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8af13b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48884, 321)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "84aa1c0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'name',\n",
       " 'host_id',\n",
       " 'host_name',\n",
       " 'neighbourhood_group',\n",
       " 'neighbourhood',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'room_type',\n",
       " 'price',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'last_review',\n",
       " 'reviews_per_month',\n",
       " 'calculated_host_listings_count',\n",
       " 'availability_365']"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odf.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "fa4f8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "notuseful = ['id',\n",
    " 'name',\n",
    " 'host_id',\n",
    " 'host_name',\n",
    " 'neighbourhood_group',\n",
    " 'neighbourhood',\n",
    " 'latitude',\n",
    " 'longitude',\n",
    " 'room_type',\n",
    " 'price',\n",
    "#  'minimum_nights',\n",
    "#  'number_of_reviews',\n",
    " 'last_review',\n",
    "#  'reviews_per_month',\n",
    "#  'calculated_host_listings_count',\n",
    "#  'availability_365'\n",
    "\n",
    "'lr_year',\n",
    "'lr_month',\n",
    "'lr_day',\n",
    "'lr_day_of_week'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "c440f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = df.drop(columns=notuseful)\n",
    "tar = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "d846e94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48884, 306)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape\n",
    "# Data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "50951962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b0ca4",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "5840b9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclearly regression problem\\nexpectation is tree is better, LR is bad at capturing non linear and categorical data\\nexpectation is boost tree should be better than RF for the outlier capture\\n    expectation failed becasue outlier ARE caputred but they are too skewed therefore messed up model\\n'"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "clearly regression problem\n",
    "expectation is tree is better, LR is bad at capturing non linear and categorical data\n",
    "expectation is boost tree should be better than RF for the outlier capture\n",
    "    expectation failed becasue outlier ARE caputred but they are too scattered therefore messed up model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d42bbe02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.82155255404183 152.8175192519252 152.382244647484\n",
      "34279 7272 7333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_trainvalid, X_test, y_trainvalid, y_test = train_test_split(Data, tar, test_size=0.15, random_state=1236)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainvalid, y_trainvalid, test_size=0.175, random_state=1236)\n",
    "print(y_train.mean(),y_valid.mean(),y_test.mean())\n",
    "print(len(y_train),len(y_valid),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "37ad4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ff45c",
   "metadata": {},
   "source": [
    "## RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e5eb0d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "022da886",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat_rf = rf_model.predict(X_train)\n",
    "y_valid_hat_rf = rf_model.predict(X_valid)\n",
    "y_test_hat_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "df1af8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.781263490328392\n",
      "67.37884564958917\n",
      "67.28394589858165\n",
      "--------------------------------\n",
      "0.8373958003463924\n",
      "-0.02505485863198942\n",
      "0.09098201422075514\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_train,y_train_hat_rf))\n",
    "print(mean_absolute_error(y_valid,y_valid_hat_rf))\n",
    "print(mean_absolute_error(y_test,y_test_hat_rf))\n",
    "print('--------------------------------')\n",
    "print(explained_variance_score(y_train,y_train_hat_rf))\n",
    "print(explained_variance_score(y_valid,y_valid_hat_rf))\n",
    "print(explained_variance_score(y_test,y_test_hat_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "9a8279e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125ea52",
   "metadata": {},
   "source": [
    "## GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f7a0782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GB_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
    "GB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "92fe92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat_GB = GB_model.predict(X_train)\n",
    "y_valid_hat_GB = GB_model.predict(X_valid)\n",
    "y_test_hat_GB = GB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "9c74da2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.48688558820223\n",
      "67.13497574993593\n",
      "68.1037591721927\n",
      "--------------------------------\n",
      "0.2933608740293152\n",
      "0.08328924574671459\n",
      "0.12499904660643657\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_train,y_train_hat_GB))\n",
    "print(mean_absolute_error(y_valid,y_valid_hat_GB))\n",
    "print(mean_absolute_error(y_test,y_test_hat_GB))\n",
    "print('--------------------------------')\n",
    "print(explained_variance_score(y_train,y_train_hat_GB))\n",
    "print(explained_variance_score(y_valid,y_valid_hat_GB))\n",
    "print(explained_variance_score(y_test,y_test_hat_GB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ee4b1",
   "metadata": {},
   "source": [
    "## XG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2710d699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "             objective='reg:absoluteerror', predictor=None, ...)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "xg_model = xgb.XGBRegressor(objective='reg:absoluteerror', n_estimators=1000, learning_rate=0.05)\n",
    "xg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0ac1efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat_xg = xg_model.predict(X_train)\n",
    "y_valid_hat_xg = xg_model.predict(X_valid)\n",
    "y_test_hat_xg = xg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "2bf838f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.38583389925893\n",
      "66.70808293926964\n",
      "68.15695159113068\n",
      "--------------------------------\n",
      "0.0637591849073027\n",
      "0.04620685288203419\n",
      "0.053133119773350224\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_train,y_train_hat_xg))\n",
    "print(mean_absolute_error(y_valid,y_valid_hat_xg))\n",
    "print(mean_absolute_error(y_test,y_test_hat_xg))\n",
    "print('--------------------------------')\n",
    "print(explained_variance_score(y_train,y_train_hat_xg))\n",
    "print(explained_variance_score(y_valid,y_valid_hat_xg))\n",
    "print(explained_variance_score(y_test,y_test_hat_xg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ad749",
   "metadata": {},
   "source": [
    "##  Lasso-L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c471866f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "L1_model = Lasso(alpha=0.1)\n",
    "L1_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "af89f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat_L1 = L1_model.predict(X_train)\n",
    "y_valid_hat_L1 = L1_model.predict(X_valid)\n",
    "y_test_hat_L1 = L1_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "6999d8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.9204455787524\n",
      "72.38747295992124\n",
      "73.09039389151674\n",
      "--------------------------------\n",
      "0.1378598102588734\n",
      "0.08345314489625366\n",
      "0.10802905754147363\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_train,y_train_hat_L1))\n",
    "print(mean_absolute_error(y_valid,y_valid_hat_L1))\n",
    "print(mean_absolute_error(y_test,y_test_hat_L1))\n",
    "print('--------------------------------')\n",
    "print(explained_variance_score(y_train,y_train_hat_L1))\n",
    "print(explained_variance_score(y_valid,y_valid_hat_L1))\n",
    "print(explained_variance_score(y_test,y_test_hat_L1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ae8c2",
   "metadata": {},
   "source": [
    "##  Ridge-L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c1398fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "L2_model = Ridge(alpha=0.5)\n",
    "L2_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "73f942f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat_L2 = L2_model.predict(X_train)\n",
    "y_valid_hat_L2 = L2_model.predict(X_valid)\n",
    "y_test_hat_L2 = L2_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "80132a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.37220508299687\n",
      "73.30383094561255\n",
      "73.7660012289345\n",
      "--------------------------------\n",
      "0.14249073977549176\n",
      "0.08147215713169176\n",
      "0.10765290944205241\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_train,y_train_hat_L2))\n",
    "print(mean_absolute_error(y_valid,y_valid_hat_L2))\n",
    "print(mean_absolute_error(y_test,y_test_hat_L2))\n",
    "print('--------------------------------')\n",
    "print(explained_variance_score(y_train,y_train_hat_L2))\n",
    "print(explained_variance_score(y_valid,y_valid_hat_L2))\n",
    "print(explained_variance_score(y_test,y_test_hat_L2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2097ef7",
   "metadata": {},
   "source": [
    "##  LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "25a975b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_LR = LinearRegression()\n",
    "model_LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "65d1cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat_LR = model_LR.predict(X_train)\n",
    "y_valid_hat_LR = model_LR.predict(X_valid)\n",
    "y_test_hat_LR = model_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "fac1ad2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.37097958172733\n",
      "6826617.000477303\n",
      "6907881.227889276\n",
      "--------------------------------\n",
      "0.1425359563233436\n",
      "-1068773236009.662\n",
      "-1341075099221.4766\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_train,y_train_hat_LR))\n",
    "print(mean_absolute_error(y_valid,y_valid_hat_LR))\n",
    "print(mean_absolute_error(y_test,y_test_hat_LR))\n",
    "print('--------------------------------')\n",
    "print(explained_variance_score(y_train,y_train_hat_LR))\n",
    "print(explained_variance_score(y_valid,y_valid_hat_LR))\n",
    "print(explained_variance_score(y_test,y_test_hat_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9301ce",
   "metadata": {},
   "source": [
    "# Improvments and follow up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "af2b86d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmore feautre engineering from name using NL models, also improvment on existing codes\\nmore feature engineering from geolocation columns\\nproper treatment of last_review column given its 1/5 nan value but significant business impact\\n'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "more feautre engineering from name using NL models, also improvment on existing codes\n",
    "more feature engineering from geolocation columns\n",
    "proper treatment of last_review column given its 1/5 nan value but significant business impact, probally 2 project, new/return and old\n",
    "figure out why XGB and GB are so bad, probabbly becasue of the outliers\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
